# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16SmvDV2dNrTNDIK_5Yxyk2dK5X2qCIlL
"""

# üåßÔ∏è Rainfall Prediction Dashboard using LSTM
# ------------------------------------------------------
# Developed for Streamlit Cloud Deployment
# By: [Harshit Pant ]
# ------------------------------------------------------

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import requests
import datetime as dt
import joblib
import time
from tensorflow.keras.models import load_model

# ------------------------------------------------------
# üß± PAGE CONFIGURATION
# ------------------------------------------------------
st.set_page_config(
    page_title="Rainfall Prediction Dashboard",
    page_icon="üåßÔ∏è",
    layout="wide",
)

# ------------------------------------------------------
# ‚öôÔ∏è LOAD MODEL AND SCALERS
# ------------------------------------------------------
@st.cache_resource
@st.cache_resource
@st.cache_resource
def load_model_and_scalers():
    model = load_model("rainfall.h5")
    feature_scaler = joblib.load("feature_scaler.pkl")
    target_scaler = joblib.load("target_scaler.pkl")
    return model, feature_scaler, target_scaler

model, feature_scaler, target_scaler = load_model_and_scalers()

# ------------------------------------------------------
# üåç WEATHER API CONFIGURATION
# ------------------------------------------------------
# üåç WEATHER API CONFIGURATION (Open-Meteo)
import requests

DEFAULT_CITY = "Mohali,IN"

# Optional: pre-defined coordinates for Indian cities
CITY_COORDS = {
    # ---------------- CITY SELECTION FOR INDIA ----------------

CITY_COORDS = {
    "Delhi": (28.6139, 77.2090),
    "Mumbai": (19.0760, 72.8777),
    "Kolkata": (22.5726, 88.3639),
    "Chennai": (13.0827, 80.2707),
    "Bengaluru": (12.9716, 77.5946),
    "Hyderabad": (17.3850, 78.4867),
    "Pune": (18.5204, 73.8567),
    "Ahmedabad": (23.0225, 72.5714),
    "Jaipur": (26.9124, 75.7873),
    "Surat": (21.1702, 72.8311),
    "Lucknow": (26.8467, 80.9462),
    "Kanpur": (26.4499, 80.3319),
    "Nagpur": (21.1458, 79.0882),
    "Indore": (22.7196, 75.8577),
    "Bhopal": (23.2599, 77.4126),
    "Patna": (25.5941, 85.1376),
    "Vadodara": (22.3072, 73.1812),
    "Ludhiana": (30.9000, 75.8573),
    "Agra": (27.1767, 78.0081),
    "Varanasi": (25.3176, 82.9739),
    "Amritsar": (31.6340, 74.8723),
    "Ranchi": (23.3441, 85.3096),
    "Guwahati": (26.1445, 91.7362),
    "Kochi": (9.9312, 76.2673),
    "Thiruvananthapuram": (8.5241, 76.9366),
    "Coimbatore": (11.0168, 76.9558),
    "Mysuru": (12.2958, 76.6394),
    "Noida": (28.5355, 77.3910),
    "Gurgaon": (28.4595, 77.0266),
    "Ghaziabad": (28.6692, 77.4538),
    "Mohali": (30.7046, 76.7179),
    "Chandigarh": (30.7333, 76.7794)
}

}

def fetch_live_weather(city):
    """Fetch live weather using Open-Meteo API."""
    lat, lon = CITY_COORDS[city]

    url = (
        f"https://api.open-meteo.com/v1/forecast?"
        f"latitude={lat}&longitude={lon}&current_weather=true&"
        "hourly=rain,relative_humidity_2m,cloudcover,wind_speed_10m"
    )

    try:
        response = requests.get(url)
        data = response.json()

        if "current_weather" not in data:
            st.error(f"API response missing expected keys: {data}")
            return None

        current = data["current_weather"]
        humidity = data["hourly"]["relative_humidity_2m"][0] if "hourly" in data else 60
        cloud = data["hourly"]["cloudcover"][0] if "hourly" in data else 40

        return {
            "date": dt.datetime.now(),
            "temparature": current["temperature"],
            "humidity": humidity,
            "windspeed": current["windspeed"],
            "winddirection": current["winddirection"],
            "cloud": cloud,
        }

    except Exception as e:
        st.error(f"Error fetching from Open-Meteo API: {e}")
        return None
def predict_rainfall(live_data: dict):
    """Make rainfall prediction using trained LSTM model with feature name auto-alignment."""
    df_live = pd.DataFrame([live_data])

    # Add time-based features if the model used them
    df_live["dayofweek"] = dt.datetime.now().weekday()
    df_live["month"] = dt.datetime.now().month

    try:
        # If scaler has stored feature names, use them
        expected_features = list(feature_scaler.feature_names_in_)
        # Auto-create missing engineered features
        for feat in expected_features:
            if feat not in df_live.columns:
                if "humidity" in feat:
                    df_live[feat] = df_live["humidity"].values[0]
                elif "cloud" in feat:
                    df_live[feat] = df_live["cloud"].values[0]
                elif "wind" in feat:
                    df_live[feat] = df_live["windspeed"].values[0]
                elif "temp" in feat:
                    df_live[feat] = df_live["temparature"].values[0]
                elif "day" in feat:
                    df_live[feat] = df_live["dayofweek"].values[0]
                elif "month" in feat:
                    df_live[feat] = df_live["month"].values[0]
                else:
                    df_live[feat] = 0  # safe default for unknown features

        # Match the exact order expected by the scaler
        X_live = df_live[expected_features]

    except AttributeError:
        # Fallback if scaler has no feature name tracking
        X_live = df_live.select_dtypes(include=[np.number])

    # Transform safely
    X_scaled = feature_scaler.transform(X_live)
    X_scaled = X_scaled.reshape((1, X_scaled.shape[1], 1))

    y_pred = model.predict(X_scaled)
    return float(target_scaler.inverse_transform(y_pred)[0][0])


# ------------------------------------------------------
# üìä LOAD HISTORICAL DATA
# ------------------------------------------------------
@st.cache_data
def load_historical_data():
    try:
        df = pd.read_csv("Synthetic_Rainfall_Dataset_1100.csv")
        if "date" in df.columns:
            df["date"] = pd.to_datetime(df["date"], errors="coerce")
            df.dropna(subset=["date"], inplace=True)
            df.set_index("date", inplace=True)
        return df
    except FileNotFoundError:
        st.error("‚ùå Historical dataset file not found. Upload `Synthetic_Rainfall_Dataset_1100.csv` to your repo.")
        return pd.DataFrame()

pdf = load_historical_data()

# ------------------------------------------------------
# üß≠ SIDEBAR CONTROLS
# ------------------------------------------------------
st.sidebar.header("‚öôÔ∏è Dashboard Controls")

city_selected = st.sidebar.selectbox(
    "Select City (India)",
    list(CITY_COORDS.keys()),
    index=list(CITY_COORDS.keys()).index("Mohali")  # default
)

auto_refresh = st.sidebar.checkbox("Auto-refresh Predictions", value=False)
refresh_rate = st.sidebar.slider("Refresh Interval (seconds)", 30, 300, 60)

st.sidebar.info("Live weather powered by Open-Meteo API")

# ------------------------------------------------------
# üåßÔ∏è MAIN DASHBOARD UI
# ------------------------------------------------------
st.title("üåßÔ∏è Rainfall Prediction Dashboard using LSTM")
st.markdown(
    """
    This interactive dashboard predicts **rainfall intensity** in real-time using a
    Long Short-Term Memory (**LSTM**) deep learning model trained on historical weather data.
    """
)

tab1, tab2, tab3, tab4 = st.tabs([
    "üìà Live Predictions", 
    "üìä Model Evaluation", 
    "üìâ Historical Trends",
    "üí¨ Weather Chatbot"
])

# -------------------- TAB 1: LIVE PREDICTIONS --------------------
with tab1:
    st.subheader("Live Weather & Predicted Rainfall")

    if "history" not in st.session_state:
        st.session_state["history"] = pd.DataFrame(columns=["date", "predicted_rainfall", "humidity", "temparature", "windspeed"])

    placeholder = st.empty()
    while True:
        live_data = fetch_live_weather(city)
        if live_data:
            rainfall_pred = predict_rainfall(live_data)

            new_entry = {
                "date": live_data["date"],
                "predicted_rainfall": rainfall_pred,
                "humidity": live_data["humidity"],
                "temparature": live_data["temparature"],
                "windspeed": live_data["windspeed"],
            }
            st.session_state["history"] = pd.concat(
                [st.session_state["history"], pd.DataFrame([new_entry])], ignore_index=True
            )

            with placeholder.container():
                col1, col2, col3 = st.columns(3)
                col1.metric("üåßÔ∏è Predicted Rainfall (mm)", f"{rainfall_pred:.2f}")
                col2.metric("üíß Humidity (%)", f"{live_data['humidity']}")
                col3.metric("üå°Ô∏è Temperature (¬∞C)", f"{live_data['temparature']:.1f}")

                # Time Series Chart
                hist_df = st.session_state["history"].tail(30)
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=hist_df["date"], y=hist_df["predicted_rainfall"],
                    mode="lines+markers", name="Predicted Rainfall"
                ))
                fig.update_layout(
                    title="Predicted Rainfall Over Time",
                    xaxis_title="Timestamp",
                    yaxis_title="Rainfall (mm)",
                    template="plotly_white"
                )
                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(hist_df.tail(10))

        if not auto_refresh:
            break
        time.sleep(refresh_rate)

# -------------------- TAB 2: MODEL EVALUATION --------------------
with tab2:
    st.subheader("Model Evaluation Metrics (from Training Phase)")
    # You can replace these placeholders with actual values from your model evaluation
    mae, mse, r2 = 0.312, 0.248, 0.917

    col1, col2, col3 = st.columns(3)
    col1.metric("üìâ MAE", f"{mae:.3f}")
    col2.metric("üìà MSE", f"{mse:.3f}")
    col3.metric("üî¢ R¬≤ Score", f"{r2:.3f}")

    st.info("These metrics represent the model's performance on the test dataset during training.")

# -------------------- TAB 3: HISTORICAL DATA --------------------
with tab3:
    st.subheader("Historical Weather Trends")
    if not pdf.empty:
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=pdf.index, y=pdf["rainfall"], mode="lines", name="Actual Rainfall"))
        fig.update_layout(
            title="Historical Rainfall Trend",
            xaxis_title="Date",
            yaxis_title="Rainfall (mm)",
            template="plotly_white"
        )
        st.plotly_chart(fig, use_container_width=True)

        st.write("### Correlation Heatmap (sample)")
        st.dataframe(pdf.corr().round(2))
    else:
        st.warning("No historical dataset loaded.")

with tab4:
    st.subheader("üí¨ Free Weather Chatbot (HuggingFace)")

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    user_msg = st.text_input("Ask anything about weather:")

    if user_msg:
        st.session_state.chat_history.append(("user", user_msg))

        bot_reply = ask_free_chatbot(user_msg)

        st.session_state.chat_history.append(("bot", bot_reply))

    # Display messages
    for role, msg in st.session_state.chat_history:
        if role == "user":
            st.markdown(f"**üßë You:** {msg}")
        else:
            st.markdown(f"**ü§ñ Bot:** {msg}")

    if st.button("üîÑ Clear Chat"):
        st.session_state.chat_history = []


# -------------------- FOOTER --------------------
st.markdown("---")
st.caption("Developed by [Your Name] ‚Ä¢ Powered by OpenWeatherMap API ‚Ä¢ Model: LSTM Neural Network")
# ---------------------- FREE CHATBOT (HuggingFace) -----------------------
import requests
import streamlit as st

HF_API_URL = "https://api-inference.huggingface.co/models/google/flan-t5-small"
HF_API_KEY = st.secrets["hf"]["api_key"]

headers = {"Authorization": f"Bearer {HF_API_KEY}"}

def ask_chatbot(prompt):
    """Free weather chatbot using HuggingFace API"""
    data = {"inputs": prompt}
    response = requests.post(HF_API_URL, headers=headers, json=data)
    try:
        return response.json()[0]["generated_text"]
    except:
        return "Sorry, the chatbot is currently busy. Try again in a few seconds."


# ---------------- CHATBOT UI ----------------

st.subheader("üå§Ô∏è Weather Chatbot")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

user_msg = st.text_input("Ask me anything about weather:")

if user_msg:
    full_prompt = f"User question about weather: {user_msg}. Respond simply, clearly, and as a weather expert."

    bot_reply = ask_chatbot(full_prompt)

    st.session_state.chat_history.append(("You", user_msg))
    st.session_state.chat_history.append(("Bot", bot_reply))

# Show chat
for sender, msg in st.session_state.chat_history:
    if sender == "You":
        st.markdown(f"**üßë‚Äçüí¨ You:** {msg}")
    else:
        st.markdown(f"**ü§ñ Bot:** {msg}")
