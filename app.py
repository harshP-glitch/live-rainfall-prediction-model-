# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16SmvDV2dNrTNDIK_5Yxyk2dK5X2qCIlL
"""

# üåßÔ∏è Rainfall Prediction Dashboard using LSTM
# ------------------------------------------------------
# Developed for Streamlit Cloud Deployment
# By: [Harshit Pant ]
# ------------------------------------------------------

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import requests
import datetime as dt
import joblib
import time
from tensorflow.keras.models import load_model

# ------------------------------------------------------
# üß± PAGE CONFIGURATION
# ------------------------------------------------------
st.set_page_config(
    page_title="Rainfall Prediction Dashboard",
    page_icon="üåßÔ∏è",
    layout="wide",
)

# ------------------------------------------------------
# ‚öôÔ∏è LOAD MODEL AND SCALERS
# ------------------------------------------------------
@st.cache_resource
@st.cache_resource
@st.cache_resource
def load_model_and_scalers():
    model = load_model("rainfall.h5")
    feature_scaler = joblib.load("feature_scaler.pkl")
    target_scaler = joblib.load("target_scaler.pkl")
    return model, feature_scaler, target_scaler

model, feature_scaler, target_scaler = load_model_and_scalers()

# ------------------------------------------------------
# üåç WEATHER API CONFIGURATION
# ------------------------------------------------------
# üåç WEATHER API CONFIGURATION (Open-Meteo)
import requests

DEFAULT_CITY = "Mohali,IN"

# Optional: pre-defined coordinates for Indian cities
CITY_COORDS = {
    "Delhi,IN": (28.6139, 77.2090),
    "Mohali,IN": (30.7046, 76.7179),
    "Mumbai,IN": (19.0760, 72.8777),
    "Bengaluru,IN": (12.9716, 77.5946),
    "Chennai,IN": (13.0827, 80.2707),
    "Kolkata,IN": (22.5726, 88.3639)
}

def fetch_live_weather(city: str):
    """Fetch live weather data using Open-Meteo API (no key required)."""
    lat, lon = CITY_COORDS.get(city, (30.7046, 76.7179))  # default Mohali

    url = (
        f"https://api.open-meteo.com/v1/forecast?"
        f"latitude={lat}&longitude={lon}"
        f"&current_weather=true"
        f"&hourly=rain,relative_humidity_2m,cloudcover,wind_speed_10m"
    )

    try:
        response = requests.get(url)
        data = response.json()

        if "current_weather" not in data:
            st.error(f"API response missing expected keys: {data}")
            return None

        current = data["current_weather"]
        humidity = data["hourly"]["relative_humidity_2m"][0] if "hourly" in data else 60
        cloud = data["hourly"]["cloudcover"][0] if "hourly" in data else 40

        return {
            "date": dt.datetime.now(),
            "temparature": current["temperature"],
            "humidity": humidity,
            "windspeed": current["windspeed"],
            "winddirection": current["winddirection"],
            "cloud": cloud,
        }

    except Exception as e:
        st.error(f"Error fetching from Open-Meteo API: {e}")
        return None
def predict_rainfall(live_data: dict):
    """Make rainfall prediction using trained LSTM model with feature name auto-alignment."""
    df_live = pd.DataFrame([live_data])

    # Add time-based features if the model used them
    df_live["dayofweek"] = dt.datetime.now().weekday()
    df_live["month"] = dt.datetime.now().month

    try:
        # If scaler has stored feature names, use them
        expected_features = list(feature_scaler.feature_names_in_)
        # Auto-create missing engineered features
        for feat in expected_features:
            if feat not in df_live.columns:
                if "humidity" in feat:
                    df_live[feat] = df_live["humidity"].values[0]
                elif "cloud" in feat:
                    df_live[feat] = df_live["cloud"].values[0]
                elif "wind" in feat:
                    df_live[feat] = df_live["windspeed"].values[0]
                elif "temp" in feat:
                    df_live[feat] = df_live["temparature"].values[0]
                elif "day" in feat:
                    df_live[feat] = df_live["dayofweek"].values[0]
                elif "month" in feat:
                    df_live[feat] = df_live["month"].values[0]
                else:
                    df_live[feat] = 0  # safe default for unknown features

        # Match the exact order expected by the scaler
        X_live = df_live[expected_features]

    except AttributeError:
        # Fallback if scaler has no feature name tracking
        X_live = df_live.select_dtypes(include=[np.number])

    # Transform safely
    X_scaled = feature_scaler.transform(X_live)
    X_scaled = X_scaled.reshape((1, X_scaled.shape[1], 1))

    y_pred = model.predict(X_scaled)
    return float(target_scaler.inverse_transform(y_pred)[0][0])


# ------------------------------------------------------
# üìä LOAD HISTORICAL DATA
# ------------------------------------------------------
@st.cache_data
def load_historical_data():
    try:
        df = pd.read_csv("Synthetic_Rainfall_Dataset_1100.csv")
        if "date" in df.columns:
            df["date"] = pd.to_datetime(df["date"], errors="coerce")
            df.dropna(subset=["date"], inplace=True)
            df.set_index("date", inplace=True)
        return df
    except FileNotFoundError:
        st.error("‚ùå Historical dataset file not found. Upload `Synthetic_Rainfall_Dataset_1100.csv` to your repo.")
        return pd.DataFrame()

pdf = load_historical_data()

# ------------------------------------------------------
# üß≠ SIDEBAR CONTROLS
# ------------------------------------------------------
st.sidebar.header("‚öôÔ∏è Dashboard Controls")
city = st.sidebar.text_input("Enter City Name", DEFAULT_CITY)
auto_refresh = st.sidebar.checkbox("Auto-refresh Predictions", value=False)
refresh_rate = st.sidebar.slider("Refresh Interval (seconds)", 30, 300, 60)
st.sidebar.markdown("---")
st.sidebar.info("Uses OpenWeatherMap for real-time weather data")

# ------------------------------------------------------
# üåßÔ∏è MAIN DASHBOARD UI
# ------------------------------------------------------
st.title("üåßÔ∏è Rainfall Prediction Dashboard using LSTM")
st.markdown(
    """
    This interactive dashboard predicts **rainfall intensity** in real-time using a
    Long Short-Term Memory (**LSTM**) deep learning model trained on historical weather data.
    """
)

tab1, tab2, tab3 = st.tabs(["üìà Live Predictions", "üìä Model Evaluation", "üìâ Historical Trends"])

# -------------------- TAB 1: LIVE PREDICTIONS --------------------
with tab1:
    st.subheader("Live Weather & Predicted Rainfall")

    if "history" not in st.session_state:
        st.session_state["history"] = pd.DataFrame(columns=["date", "predicted_rainfall", "humidity", "temparature", "windspeed"])

    placeholder = st.empty()
    while True:
        live_data = fetch_live_weather(city)
        if live_data:
            rainfall_pred = predict_rainfall(live_data)

            new_entry = {
                "date": live_data["date"],
                "predicted_rainfall": rainfall_pred,
                "humidity": live_data["humidity"],
                "temparature": live_data["temparature"],
                "windspeed": live_data["windspeed"],
            }
            st.session_state["history"] = pd.concat(
                [st.session_state["history"], pd.DataFrame([new_entry])], ignore_index=True
            )

            with placeholder.container():
                col1, col2, col3 = st.columns(3)
                col1.metric("üåßÔ∏è Predicted Rainfall (mm)", f"{rainfall_pred:.2f}")
                col2.metric("üíß Humidity (%)", f"{live_data['humidity']}")
                col3.metric("üå°Ô∏è Temperature (¬∞C)", f"{live_data['temparature']:.1f}")

                # Time Series Chart
                hist_df = st.session_state["history"].tail(30)
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=hist_df["date"], y=hist_df["predicted_rainfall"],
                    mode="lines+markers", name="Predicted Rainfall"
                ))
                fig.update_layout(
                    title="Predicted Rainfall Over Time",
                    xaxis_title="Timestamp",
                    yaxis_title="Rainfall (mm)",
                    template="plotly_white"
                )
                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(hist_df.tail(10))

        if not auto_refresh:
            break
        time.sleep(refresh_rate)

# -------------------- TAB 2: MODEL EVALUATION --------------------
with tab2:
    st.subheader("Model Evaluation Metrics (from Training Phase)")
    # You can replace these placeholders with actual values from your model evaluation
    mae, mse, r2 = 0.312, 0.248, 0.917

    col1, col2, col3 = st.columns(3)
    col1.metric("üìâ MAE", f"{mae:.3f}")
    col2.metric("üìà MSE", f"{mse:.3f}")
    col3.metric("üî¢ R¬≤ Score", f"{r2:.3f}")

    st.info("These metrics represent the model's performance on the test dataset during training.")

# -------------------- TAB 3: HISTORICAL DATA --------------------
with tab3:
    st.subheader("Historical Weather Trends")
    if not pdf.empty:
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=pdf.index, y=pdf["rainfall"], mode="lines", name="Actual Rainfall"))
        fig.update_layout(
            title="Historical Rainfall Trend",
            xaxis_title="Date",
            yaxis_title="Rainfall (mm)",
            template="plotly_white"
        )
        st.plotly_chart(fig, use_container_width=True)

        st.write("### Correlation Heatmap (sample)")
        st.dataframe(pdf.corr().round(2))
    else:
        st.warning("No historical dataset loaded.")

# -------------------- FOOTER --------------------
st.markdown("---")
st.caption("Developed by [Your Name] ‚Ä¢ Powered by OpenWeatherMap API ‚Ä¢ Model: LSTM Neural Network")
# =====================================
# ü§ñ Weather Conversational Chatbot
# =====================================
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

@st.cache_resource
def load_llm():
    model_name = "microsoft/DialoGPT-small"   # lightweight conversational model
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name)
    return tokenizer, model

tokenizer, model = load_llm()

st.markdown("## üå§Ô∏è Smart Weather Chatbot")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

def local_llm_response(prompt):
    """Generate a conversational reply using the offline LLM with context memory."""
    history = " ".join([msg for role, msg in st.session_state.chat_history])
    inputs = tokenizer.encode(history + prompt + tokenizer.eos_token, return_tensors="pt")
    outputs = model.generate(
        inputs,
        max_length=200,
        pad_token_id=tokenizer.eos_token_id,
        temperature=0.8,
        top_p=0.9,
        do_sample=True
    )
    reply = tokenizer.decode(outputs[:, inputs.shape[-1]:][0], skip_special_tokens=True)
    return reply

# --- Chat Interface ---
user_input = st.chat_input("Ask me anything about the weather, rainfall, or climate...")

if user_input:
    st.session_state.chat_history.append(("üë§", user_input))
    # Combine your model with chatbot logic
    if any(w in user_input.lower() for w in ["rain", "forecast", "rainfall"]):
        city = st.session_state.get("city", "Mohali,IN")
        weather = fetch_live_weather(city)
        if weather:
            rainfall_pred = predict_rainfall(weather)
            summary = f"In {city}, predicted rainfall is {rainfall_pred:.2f} mm."
            bot_reply = local_llm_response(f"{summary} Also explain what this means for farmers.")
        else:
            bot_reply = "I couldn't get live weather data right now."
    else:
        bot_reply = local_llm_response(user_input)

    st.session_state.chat_history.append(("ü§ñ", bot_reply))

# --- Display Chat ---
for role, text in st.session_state.chat_history:
    st.markdown(f"**{role}:** {text}")
